{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"03-DL-Deep Learning for Image Data (Transfer Learning) 04.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"eDD5o7dAhiy6","executionInfo":{"status":"ok","timestamp":1604997059949,"user_tz":-420,"elapsed":775,"user":{"displayName":"Tú Vũ","photoUrl":"","userId":"10869908730657653050"}},"outputId":"da9ba66d-4c21-4f96-9319-48179be2d18e","colab":{"base_uri":"https://localhost:8080/"}},"source":["# Mount drive \n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NZTR6lvERzaG"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YeWXb90jhvWU","executionInfo":{"status":"ok","timestamp":1602680594669,"user_tz":-420,"elapsed":902,"user":{"displayName":"Tú Vũ","photoUrl":"","userId":"10869908730657653050"}},"outputId":"aa42fcfd-f123-4b7e-d2f6-396eb00626f1","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["path = \"//content//gdrive//My Drive//My DeepLearning//\"\n","import os\n","os.path.isdir(path)   "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"AlbjQqVZhgI4"},"source":["import numpy as np\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","from PIL import Image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5CP-3KBHhgI8"},"source":["import keras\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.applications import ResNet50\n","from keras.applications.resnet50 import preprocess_input\n","from keras import Model, layers\n","from keras.models import load_model, model_from_json\n","import tensorflow as tf\n","import PIL"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XufvMczLAmp6"},"source":["#%cd /content/gdrive/'My Drive'/'My DeepLearning'/'Practice'\n","#!unzip 'alien-vs-predator-images.zip'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ijKVIvpVhgJG","executionInfo":{"status":"ok","timestamp":1602680842848,"user_tz":-420,"elapsed":909,"user":{"displayName":"Tú Vũ","photoUrl":"","userId":"10869908730657653050"}},"outputId":"fd21b326-ad94-4bd8-aef1-6a16557181cf","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# path for Kaggle kernels\n","input_path = path + \"/Alien-vs-Predator-images/\"\n","os.path.isdir(input_path) "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"skkISgL6hgJJ","executionInfo":{"status":"ok","timestamp":1602681409350,"user_tz":-420,"elapsed":919,"user":{"displayName":"Tú Vũ","photoUrl":"","userId":"10869908730657653050"}},"outputId":"3f3344ce-ea87-4ebd-c166-3fe4cfb27ce4","colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["train_datagen = ImageDataGenerator(\n","    shear_range=10,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    preprocessing_function=preprocess_input)\n","\n","train_generator = train_datagen.flow_from_directory(\n","    input_path + 'train',\n","    batch_size=32,\n","    class_mode='binary',\n","    target_size=(224,224))\n","\n","validation_datagen = ImageDataGenerator(\n","    preprocessing_function=preprocess_input)\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    input_path + 'validation',\n","    shuffle=False,\n","    class_mode='binary',\n","    target_size=(224,224))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 694 images belonging to 2 classes.\n","Found 200 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Oe-lUQoChgJM"},"source":["conv_base = ResNet50(\n","    include_top=False,\n","    weights='imagenet')\n","\n","for layer in conv_base.layers:\n","    layer.trainable = False"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qZhWMZpahgJP"},"source":["x = conv_base.output\n","x = layers.GlobalAveragePooling2D()(x)\n","x = layers.Dense(128, activation='relu')(x) \n","predictions = layers.Dense(4, activation='softmax')(x)\n","model = Model(conv_base.input, predictions)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ehbq29JShgJR"},"source":["optimizer = keras.optimizers.Adam()\n","model.compile(loss='sparse_categorical_crossentropy',\n","              optimizer=optimizer,\n","              metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9FI7xs4bhgJU","executionInfo":{"status":"ok","timestamp":1602682140922,"user_tz":-420,"elapsed":147513,"user":{"displayName":"Tú Vũ","photoUrl":"","userId":"10869908730657653050"}},"outputId":"44111ccf-4aa1-4fcf-97a2-c4a8b4633734","colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["history = model.fit_generator(generator=train_generator,\n","                              steps_per_epoch=347 // 32,  # added in Kaggle\n","                              epochs=3,\n","                              validation_data=validation_generator,\n","                              validation_steps=10  # added in Kaggle\n","                             )"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/3\n","10/10 [==============================] - ETA: 0s - loss: 0.1652 - accuracy: 0.9387WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10 batches). You may need to use the repeat() function when building your dataset.\n","10/10 [==============================] - 57s 6s/step - loss: 0.1652 - accuracy: 0.9387 - val_loss: 0.4756 - val_accuracy: 0.8500\n","Epoch 2/3\n","10/10 [==============================] - 37s 4s/step - loss: 0.1490 - accuracy: 0.9344\n","Epoch 3/3\n","10/10 [==============================] - 34s 3s/step - loss: 0.1115 - accuracy: 0.9531\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YM3rBG6ShgJW","executionInfo":{"status":"error","timestamp":1602682287045,"user_tz":-420,"elapsed":914,"user":{"displayName":"Tú Vũ","photoUrl":"","userId":"10869908730657653050"}},"outputId":"1dacde06-a4fd-4c62-8934-5e3e64dbf03e","colab":{"base_uri":"https://localhost:8080/","height":460}},"source":["# save  \n","model.save(path + 'Transfer Learning Models/Alien-vs-Predator-images.h5')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-5e00b92ac8e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'Transfer Learning Models/Alien-vs-Predator-images.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1977\u001b[0m     \"\"\"\n\u001b[1;32m   1978\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1979\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m   def save_weights(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    129\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    130\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 131\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    132\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mopened_new_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n","\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: Unable to create file (unable to open file: name = '//content//gdrive//My Drive//My DeepLearning//Practice//Transfer Learning Models/Alien-vs-Predator-images.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)"]}]},{"cell_type":"code","metadata":{"id":"2L_nj5KmhgJY"},"source":["# load\n","model = load_model(path + 'Transfer Learning Models/Object-Dataset-images.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CXZupFejhgJg","executionInfo":{"status":"error","timestamp":1602682341922,"user_tz":-420,"elapsed":911,"user":{"displayName":"Tú Vũ","photoUrl":"","userId":"10869908730657653050"}},"outputId":"479746e6-65c1-4b03-80f0-e9490cc5190c","colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["import os\n","test_path = input_path + \"/validation/cats/\"\n","validation_img_paths = os.listdir(test_path)\n","len(validation_img_paths)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-45d31e586b8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/validation/cats/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvalidation_img_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_img_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '//content//gdrive//My Drive//My DeepLearning//Practice///Alien-vs-Predator-images//validation/cats/'"]}]},{"cell_type":"code","metadata":{"id":"my5psNOChgJj"},"source":["img_list = [Image.open(test_path + img_path) for img_path in validation_img_paths]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wAzqP8MlhgJl"},"source":["validation_batch = np.stack([preprocess_input(np.array(img.resize((224,224))))\n","                             for img in img_list])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_vTvLJXhgJn","executionInfo":{"status":"ok","timestamp":1600421685691,"user_tz":-420,"elapsed":6273,"user":{"displayName":"Anh Tuan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ9KyiTpC6MMKMLCBAkvhJJ9v-lY1rLIrJhzBO=s64","userId":"03546433032765854702"}},"outputId":"b0a449b5-f5f2-4733-f824-8c3dcea09494","colab":{"base_uri":"https://localhost:8080/","height":553}},"source":["pred_probs = model.predict(validation_batch)\n","pred_probs"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[9.99597371e-01, 4.02621867e-04, 5.19766807e-08, 4.05770351e-08],\n","       [9.99970675e-01, 2.92777349e-05, 9.98223015e-09, 5.84639803e-09],\n","       [9.99998331e-01, 1.72608623e-06, 2.07180406e-09, 1.59435654e-09],\n","       [9.99931335e-01, 6.84539846e-05, 3.11005230e-08, 2.20819956e-07],\n","       [9.99957323e-01, 4.26582083e-05, 2.17425522e-09, 1.29526417e-10],\n","       [9.98211265e-01, 1.78640394e-03, 2.35914376e-06, 3.29538992e-08],\n","       [9.99732912e-01, 2.66949559e-04, 7.52452181e-08, 2.53056758e-08],\n","       [9.99886513e-01, 1.13495560e-04, 1.36319322e-09, 2.82439877e-10],\n","       [9.99978423e-01, 2.12350242e-05, 6.61911912e-08, 2.32427524e-07],\n","       [9.99973178e-01, 2.68660078e-05, 1.24816157e-08, 1.97355767e-08],\n","       [9.99963999e-01, 3.52622810e-05, 3.75891943e-07, 3.47712870e-07],\n","       [9.99969602e-01, 3.03032466e-05, 3.06388053e-08, 6.38174242e-08],\n","       [9.99989986e-01, 1.00099314e-05, 1.36310818e-09, 7.64964447e-09],\n","       [9.99931455e-01, 6.84051847e-05, 4.63590091e-08, 8.14936811e-08],\n","       [9.99980450e-01, 1.95456523e-05, 5.55924307e-10, 1.05850377e-10],\n","       [9.99994874e-01, 5.09095162e-06, 3.18635673e-09, 1.12021432e-08],\n","       [9.99962330e-01, 3.76109747e-05, 1.37326932e-08, 6.01687988e-09],\n","       [9.99471605e-01, 5.28433535e-04, 1.47144554e-08, 4.48496040e-09],\n","       [9.99992251e-01, 7.80640585e-06, 6.64095845e-09, 5.66050984e-09],\n","       [9.99996662e-01, 3.30850139e-06, 3.57276375e-10, 2.94439084e-10],\n","       [9.99985814e-01, 1.41927585e-05, 8.82674467e-09, 1.08430704e-08],\n","       [9.99977112e-01, 2.29060461e-05, 2.70435994e-08, 2.12368469e-08],\n","       [9.99774039e-01, 2.26006669e-04, 1.26548427e-09, 6.09810147e-10],\n","       [9.99649048e-01, 3.50900926e-04, 1.81314679e-08, 1.55480206e-09],\n","       [9.99980807e-01, 1.92056705e-05, 2.06709156e-08, 5.00636368e-08],\n","       [9.99991179e-01, 8.82778932e-06, 1.42996415e-08, 2.47991121e-08],\n","       [9.99693155e-01, 3.04115703e-04, 1.87128273e-06, 8.02442116e-07],\n","       [9.99651432e-01, 3.48301517e-04, 8.35186071e-08, 1.22137891e-07],\n","       [9.98249173e-01, 1.74972008e-03, 1.04349942e-06, 6.18826661e-08],\n","       [9.99994993e-01, 4.99186990e-06, 1.63547984e-08, 5.54535795e-09]],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"ixcbsIyphgJx","executionInfo":{"status":"ok","timestamp":1600421707782,"user_tz":-420,"elapsed":1185,"user":{"displayName":"Anh Tuan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ9KyiTpC6MMKMLCBAkvhJJ9v-lY1rLIrJhzBO=s64","userId":"03546433032765854702"}},"outputId":"2e023bb2-91da-4734-8070-23fc6e7d7e2a","colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["import numpy as np\n","ObjectList = [\"cats\", \"dogs\", \"horses\", \"humans\"]\n","index_max = np.argmax(pred_probs[0])\n","value_max = np.max(pred_probs[0])\n","print(ObjectList[index_max])\n","print(value_max)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cats\n","0.9995974\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pefhIiuthgJ1"},"source":["import matplotlib.pyplot as plt\n","from keras.preprocessing import image\n","\n","i = 0\n","for filename in validation_img_paths:\n","    img_path = test_path + filename\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","    \n","    index_max = np.argmax(pred_probs[i])\n","    value_max = np.max(pred_probs[i])\n","    i = i + 1\n","\n","    plt.imshow(img)\n","    plt.show()\n","    display(ObjectList[index_max] + \" with probs \" + str(value_max))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zxzcVu_nhgJ3","executionInfo":{"status":"ok","timestamp":1600421733814,"user_tz":-420,"elapsed":1434,"user":{"displayName":"Anh Tuan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ9KyiTpC6MMKMLCBAkvhJJ9v-lY1rLIrJhzBO=s64","userId":"03546433032765854702"}},"outputId":"ff416253-bc8e-411f-b4b4-5a092297ed95","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import os\n","test_path = input_path + \"/validation/humans/\"\n","validation_img_paths = os.listdir(test_path)\n","display(len(validation_img_paths))\n","img_list = [Image.open(test_path + img_path) for img_path in validation_img_paths]\n","validation_batch = np.stack([preprocess_input(np.array(img.resize((224,224)))) for img in img_list])\n"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["30"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"SMGiZNAbhgJ6","executionInfo":{"status":"ok","timestamp":1600421741537,"user_tz":-420,"elapsed":5439,"user":{"displayName":"Anh Tuan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiQ9KyiTpC6MMKMLCBAkvhJJ9v-lY1rLIrJhzBO=s64","userId":"03546433032765854702"}},"outputId":"ca343f87-f192-47e3-bc6d-ada6a5add57e","colab":{"base_uri":"https://localhost:8080/","height":553}},"source":["pred_probs = model.predict(validation_batch)\n","pred_probs"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5.99968298e-05, 5.84856789e-05, 4.14563436e-03, 9.95735884e-01],\n","       [5.81841823e-06, 9.29396265e-05, 1.70870102e-04, 9.99730408e-01],\n","       [5.42377757e-06, 1.45743479e-06, 4.97277069e-05, 9.99943376e-01],\n","       [1.98235466e-05, 3.80492493e-05, 3.66392014e-05, 9.99905467e-01],\n","       [2.53130303e-04, 5.07366727e-04, 1.60601630e-03, 9.97633457e-01],\n","       [4.16677467e-05, 1.69345731e-04, 2.66895932e-03, 9.97120023e-01],\n","       [1.73495704e-04, 9.08243121e-04, 1.24689052e-03, 9.97671306e-01],\n","       [5.08745279e-06, 3.66085696e-05, 1.08102868e-04, 9.99850154e-01],\n","       [4.66994788e-06, 2.11982679e-05, 8.68271527e-05, 9.99887347e-01],\n","       [2.25727345e-05, 5.58623287e-04, 9.86883938e-01, 1.25348847e-02],\n","       [1.91797371e-05, 2.73923826e-04, 5.78048965e-03, 9.93926466e-01],\n","       [3.86954162e-05, 2.04208645e-05, 4.19897970e-06, 9.99936700e-01],\n","       [8.61486420e-04, 4.42044530e-03, 2.63167620e-01, 7.31550455e-01],\n","       [1.00391353e-05, 5.35686922e-05, 1.61464289e-02, 9.83789980e-01],\n","       [2.27166265e-06, 1.01901387e-04, 5.80000342e-04, 9.99315858e-01],\n","       [1.20725317e-05, 5.38562483e-04, 8.87401462e-01, 1.12047933e-01],\n","       [7.84311618e-04, 8.29045457e-05, 1.05310821e-04, 9.99027491e-01],\n","       [2.60278994e-05, 8.62571585e-04, 2.78236461e-03, 9.96329010e-01],\n","       [3.29673503e-06, 1.83324596e-06, 2.19686663e-05, 9.99972939e-01],\n","       [1.77043567e-05, 5.79217476e-06, 1.35489227e-05, 9.99962926e-01],\n","       [3.11677693e-04, 3.97809735e-03, 6.40464127e-01, 3.55246067e-01],\n","       [1.93238920e-05, 6.09937933e-06, 9.31409431e-06, 9.99965310e-01],\n","       [2.38801260e-03, 7.32896701e-02, 1.06415853e-01, 8.17906439e-01],\n","       [2.68983058e-05, 1.82382966e-04, 6.63549230e-02, 9.33435738e-01],\n","       [4.25454491e-05, 3.35601944e-05, 1.36565122e-05, 9.99910235e-01],\n","       [6.25636721e-06, 3.47654386e-05, 9.26305875e-05, 9.99866366e-01],\n","       [1.08976725e-04, 4.89876875e-05, 4.70624145e-05, 9.99795020e-01],\n","       [7.75565786e-05, 3.15714465e-03, 3.10674240e-03, 9.93658602e-01],\n","       [1.57470986e-05, 2.96492712e-04, 2.07820165e-04, 9.99479949e-01],\n","       [1.57470986e-05, 2.96492712e-04, 2.07820165e-04, 9.99479949e-01]],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"QztddzOOhgJ8","executionInfo":{"status":"error","timestamp":1602682354352,"user_tz":-420,"elapsed":915,"user":{"displayName":"Tú Vũ","photoUrl":"","userId":"10869908730657653050"}},"outputId":"26c145e5-fac9-4224-86a1-0b69c10be15e","colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["import matplotlib.pyplot as plt\n","from keras.preprocessing import image\n","\n","i = 0\n","for filename in validation_img_paths:\n","    img_path = test_path + filename\n","    img = image.load_img(img_path, target_size=(224, 224))\n","    x = image.img_to_array(img)\n","    x = np.expand_dims(x, axis=0)\n","    x = preprocess_input(x)\n","\n","    plt.imshow(img)\n","    plt.show()\n","    \n","    index_max = np.argmax(pred_probs[i])\n","    value_max = np.max(pred_probs[i])\n","    i = i + 1\n","    \n","    display(ObjectList[index_max] + \" with probs \" + str(value_max))"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-b538207e504d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidation_img_paths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'validation_img_paths' is not defined"]}]}]}